{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb568f-ddb9-4cbf-8f03-06aaae03cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy #Library required for Twitter API\n",
    "import csv, re\n",
    "import pandas as pd\n",
    "import os\n",
    "import wget\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3cbdb-ea27-4cf0-a3dd-1c1265fe960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"SWH2kMSUPgVwPY6n93cE8CWcZ\"\n",
    "consumer_secret = \"YdBvr3akX0IxcfsbrBgH8yduVCtamuNH1KEAn5HKZNULCULT8R\"\n",
    "access_key = \"1581790256847884288-F4UKcWsjRjV7pNAOKQvVAIBYdIMLHM\"\n",
    "access_secret = \"MQxx0pa3cotEmgwyj66t7SQqNUmHXOlCNJgDBGxyodh3G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5950f26-f4d1-46fa-b70f-17c5920336ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68cd57-9016-4f13-83e8-f26d7093a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#CarAccidents\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0f001-9d83-493e-b9c7-5666628a5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#roadaccident\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a0c17-225f-4b80-9a46-31f05346343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#RoadDeaths\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e71cbb-d7dd-4356-9982-5626b4e09055",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#CarCrashes\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ae99c-1ece-477e-870c-0320c5842b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#baddrivers\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67247d6-00e3-430e-9185-858ce7e85d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#roaddangers\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc2f1b-7a9b-4471-b822-5a8958ce19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#DrowsyDriving\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b8ba9-3503-4417-a95e-cb12f4ad3101",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#DrunkDriving\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef5428-af86-465f-b990-223245e6da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#RoadFatalities\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5b66e-3ef0-4b82-a3f9-11b593d81a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#TrafficDeaths\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1858be51-cf8e-45f3-9c79-26cf7a37188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#OverSpeeding\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35fb272-8c06-4626-adfd-9413b8bdc1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#carcollision\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed162b1-7e27-4485-9849-ea4df66b76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#trafficaccident\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36218b51-1336-415b-ae25-d1abdfef0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#truckaccident\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9232e4-fb18-4f98-a299-a0dfc87271f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#carblast\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a8e813-d94f-4c6a-8752-11a981aa8298",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#carcollision\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0bd68c-4113-4fe5-a1ec-fa168931edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#carwreck\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47fbd6-e6c3-4e00-be67-77eba57f9539",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_phrase= \"#hitandrun\"\n",
    "# Name of csv file to be created\n",
    "fname = hashtag_phrase\n",
    "    \n",
    "# Open the spreadsheet\n",
    "with open('/Users/sonalibandi/Desktop/all_data/%s.csv' % (fname), 'w', encoding=\"utf-8\") as file:\n",
    "        w = csv.writer(file)\n",
    "        # w.writerow(['tweet_id','timestamp', 'tweet_text', 'username', 'all_hashtags', 'location', \n",
    "        #             'followers_count', 'retweet_count', 'favorite_count'])\n",
    "        for tweet in tweepy.Cursor(api.search_tweets, q=hashtag_phrase+' -filter:retweets',count=2, lang='en', tweet_mode='extended', since_id=\"2022-04-19\").items():\n",
    "            row = tweet\n",
    "            w.writerow([tweet.id_str,\n",
    "                        tweet.created_at, \n",
    "                        tweet.full_text.replace('\\n',' '), \n",
    "                        tweet.user.screen_name, \n",
    "                        [e['text'] for e in tweet._json['entities']['hashtags']],  \n",
    "                        tweet.user.location, \n",
    "                        tweet.user.followers_count, \n",
    "                        tweet.retweet_count, \n",
    "                        tweet.favorite_count,\n",
    "                        tweet.user.id_str,\n",
    "                        tweet.retweeted, \n",
    "                        tweet.source])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea45cb8d-b899-4af2-b7ed-e911af4c0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d894f4-5288-456c-a145-694847ce20d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d7606f-ea6f-4efa-81fc-a427abe203fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from venv import create\n",
    "import tweepy\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69d5c8-2a80-4c34-8e3e-38cbdd7699b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "tweetdata = pd.read_csv('/Users/sonalibandi/Desktop/all_data/final1.csv', index_col=False, delimiter = ',' ,on_bad_lines='skip')\n",
    "tweetdata.head()\n",
    "tweetdata = tweetdata.where((pd.notnull(tweetdata)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2399b-b829-45ff-a700-8c17ed152bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = MySQLdb.connect (host=\"localhost\" , user=\"root\" , passwd=\"rootroot\" ,db=\"accidents\")\n",
    "cursor = database.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0775ff-2674-476d-b908-95c52f37a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DROP TABLE IF EXISTS accidents.User_details;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b25018e-7ce5-465d-a34e-037333bc011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('CREATE TABLE IF NOT EXISTS accidents.User_details(User_ID bigint(50) primary key, Username varchar(50) not null, Follower_count int(10), Location varchar(50));')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e8868-dd59-45a3-b622-0bde6b4994f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/sonalibandi/Desktop/all_data/final1.csv', header=None, delimiter = ';').fillna('None')\n",
    "\n",
    "# header = next(csv_data)\n",
    "\n",
    "# print(header)\n",
    "# print(df)\n",
    "\n",
    "# print('Importing the CSV Files')\n",
    "\n",
    "for row in df.to_numpy():\n",
    "    row = [str(x) for x in row]\n",
    "    # print(row)\n",
    "    r = [row[9],row[3],row[6],row[5]]\n",
    "    # print(len(r))\n",
    "    # print(r)\n",
    "    o = False\n",
    "    for s in r:\n",
    "        if len(str(s))==0:\n",
    "            o = True\n",
    "        if o:\n",
    "            continue\n",
    "        try:\n",
    "            cursor.execute('INSERT INTO accidents.User_details VALUES (%s,%s,%s,%s)',r)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "database.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54514d-0644-49d4-996c-def132a40fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('DROP TABLE IF EXISTS accidents.Tweets_table;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c414e4f0-572f-4eff-91c1-c97e3485e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/sonalibandi/Desktop/all_data/final1.csv', header=None, delimiter = ';').fillna('None')\n",
    "\n",
    "# header = next(csv_data)\n",
    "\n",
    "# print(header)\n",
    "# print(df)\n",
    "\n",
    "# print('Importing the CSV Files')\n",
    "\n",
    "for row in df.to_numpy():\n",
    "    row = [str(x) for x in row]\n",
    "    # print(row)\n",
    "    r = [row[9],row[0],row[2],row[7],row[10],row[11],row[8],row[4]]\n",
    "    # print(len(r))\n",
    "    print(r[0])\n",
    "    o = False\n",
    "    for s in r:\n",
    "        if len(str(s))==0:\n",
    "            o = True\n",
    "        if o:\n",
    "            continue\n",
    "        try:\n",
    "            cursor.execute('INSERT INTO accidents.Tweets_table VALUES (%s,%s,%s,%s,%s,%s,%s,%s)',r)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "database.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2739de0-a08c-43fe-854d-e76bc7492126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc859b94-679a-4f23-b238-26a77ae4fcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596487b-3096-4ad5-918b-6f7ac60763c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
